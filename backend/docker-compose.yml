version: '3.8'

services:
  gateway:
    build:
      context: ./gateway
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - shared_data:/usr/local/app/data
      - gateway_logs:/usr/local/app/
    environment:
      - PREPROCESS_SERVICE_URL=http://preprocess:8001/preprocess/
      - WHISPER_SERVICE_URL=http://whisper:8002/whisper/
      - SUMMARIZATION_SERVICE_URL=http://summarization:8003/summlization/
      - TZ=Asia/Bangkok
    restart: unless-stopped
    networks:
      - meeting_network
    depends_on:
      - preprocess
      - whisper
      - summarization

  preprocess:
    build:
      context: ./preprocess
      dockerfile: Dockerfile
    volumes:
      - shared_data:/usr/local/app/data
      - preprocess_logs:/usr/local/app/
    environment:
      - TZ=Asia/Bangkok
    restart: unless-stopped
    networks:
      - meeting_network

  whisper:
    build:
      context: ./whisper
      dockerfile: Dockerfile
    volumes:
      - shared_data:/usr/local/app/data
      - whisper_logs:/usr/local/app/
      - whisper_cache:/home/app/.cache
    environment:
      - TZ=Asia/Bangkok
      - MODEL_ID=openai/whisper-large-v3-turbo
      - LANGUAGE=th
    # GPU Support (uncomment if NVIDIA Container Toolkit is installed)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - meeting_network

  summarization:
    build:
      context: ./summarization
      dockerfile: Dockerfile
    volumes:
      - shared_data:/usr/local/app/data
      - summarization_logs:/usr/local/app/
    environment:
      - TZ=Asia/Bangkok
      - MODEL_ID=llama3
      - OLLAMA_HOST=http://ollama:11434
      - MAX_TOKENS=4096
      - TEMPERATURE=0.2
    depends_on:
      - ollama
    restart: unless-stopped
    networks:
      - meeting_network

  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    networks:
      - meeting_network
    # GPU Support (uncomment if NVIDIA Container Toolkit is installed)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

networks:
  meeting_network:
    driver: bridge

volumes:
  shared_data:
    driver: local
  gateway_logs:
    driver: local
  preprocess_logs:
    driver: local
  whisper_logs:
    driver: local
  summarization_logs:
    driver: local
  whisper_cache:
    driver: local
  ollama_data:
    driver: local