# VAD (Voice Activity Detection) Service 

## Overview 

This microservice analyzes audio files to detect **speech segments** using a VAD model (e.g., Silero VAD). It is designed as the **third stage** in an audio processing pipelineâ€”executed **after preprocessing and before speaker diarization or ASR (Whisper).**

---

## âœ¨ Features

- ğŸµ Outputs 16 kHz, mono, 16-bit PCM WAV format
- ğŸªš Splits long audio into speech-only chunks
- ğŸ¯ Outputs timestamps (start, end) of speech regions
- ğŸªµ Optional: Save audio chunks to disk
- ğŸš¥ Healthcheck and service liveness endpoints included
- ğŸ›¡ï¸ Designed for internal secure microservice pipelines (Docker-ready)

---

## ğŸ“¦ Project Structure
```bash 
+-- vad/
â”œâ”€â”€ main.py # FastAPI app entrypoint
â”œâ”€â”€ routers/
â”‚ â”œâ”€â”€ root.py # Root '/' liveness endpoint
â”‚ â”œâ”€â”€ healthcheck.py # Dependency check (FFmpeg)
â”‚ â””â”€â”€ vad.py # VAD endpoint
â”œâ”€â”€ services/
â”‚ â””â”€â”€ vad_service.py # FFmpeg call logic
â”œâ”€â”€ models/
â”‚ â””â”€â”€ preprocess_request.py # Pydantic request model
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ logger.py # Global logger
â”‚ â””â”€â”€ ffmpeg_checker.py # FFmpeg availability check
â”œâ”€â”€ config/
  â””â”€â”€ settings.py # Timeout config
```

---

## ğŸš€ API Endpoints

| Method | Route              | Description                        |
|--------|-------------------|-------------------------------------|
| `GET`  | `/`               | Service liveness check              |
| `GET`  | `/healthcheck`    | Dependency check (model)            |
| `POST` | `/vad/`           | Perform VAD on WAV input            |

---

##  ğŸ§ª VAD Behavior

- Input: WAV audio file path
- Output: 
    - JSON list of speech segments 
    - (Optional) saved `wav` chunks for each segment
- Internal logic:
  ```python
  await asyncio.to_thread(vad_pipeline, file_path)
- Process waveform
- Predict voice probabilities 
- Return regions with speech (thresholded)

### ğŸ›  Startup Behavior
On service startup, the application performs a dependency check to ensure VAD model is available:

```python
@asynccontextmanager
async def lifespan(app: FastAPI): 
    logger.info("ğŸš€ Loading VAD model...")
    await load_vad_model()
    logger.info("âœ… VAD model ready")
    yield
```

### ğŸ“¥ Example Request
POST (`/vad/`)
<!-- TODO: implement chunk folder chunk logic -->
```json
{
    "input_path": "/data/{work_id}/converted/video.mp4",
    "output_dir": "/data/{work_id}/chunk/"
}
```

Response: 
```json 
[
    {
        "start": 3.12, 
        "end": 7.85, 
        "segment_path": "/data/{work_id}/chunk/audio_000.wav"
    },
    {
        "start": 12.01, 
        "end": 17.49, 
        "segment_path": "data/{work_id}/chunk/audio_001.wav"
    }
]
```

ğŸ§ª Optional Enhancements
<!-- TODO: must do -->
- [ ] Write new docker image
 <!--  -->
- [ ] Optional: make VAD log to file
- [ ] Make VAD Output as Chunk
- [ ] Add `min_speech_sec` and `min_silence_sec` params
- [ ] Support batch mode
- [ ] Model selection via config
- [x] Unit tests for segment logic

### ğŸ“„ Requirements 
- Python 3.11+
- FastAPI
- pyannote.audio

### ğŸ§‘â€ğŸ’» Author
- yodsran 

### ğŸ“Œ Note
This service is intended to run internally as part of a multi-stage AI pipeline and is not exposed to the public internet.

<!-- Test command -->
<!-- ~/meeting-summalization/backend$ PYTHONPATH=. pytest ./vad/tests -->